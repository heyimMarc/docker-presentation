<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Schenker Techtalk - Docker</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css">
		<link rel="stylesheet" href="css/theme/schenker-theme.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
	<?php echo "Hello ".($_ENV["NAME"]?$_ENV["NAME"]:"world")."!"; ?>
	<div class="logo"></div>
		<div class="reveal">

			<div class="slides">
				<section>
					<h2>Schenker AG TechTalk</h1>
					<h4>Docker</h3>
						<img class="no-boarder" data-src="images/docker.svg" height="150pt" width="150pt">
						<aside class="notes">
							Keep calm and breath Marc :) and please don't forget to introduce yourself.
						</aside>
				</section>
				<section>
					<section>
						<h2>What is Docker?</h2>
						<img class="no-boarder" data-src="images/isolation.jpg" height="300pt" width="300pt"/>
						<aside class="notes">
							Docker is a Tool for running Applications in an isolated environment.
							It gives you advantages similar running your application inside of a virtual machine.
						</aside>
					</section>
					<section>
						<ol>
							<li>Same environment</li>
							<li>Sandbox Projects</li>
							<li>It just works</li>
						</ol>

						<aside class="notes">
							1. **Same environment**
							Some of those advantages are, your app always runs in exactly the same environment so you don’t get inconsistencies and how it behaves.
							If it works on your computer, it works on every computer, it works on the live server and always acts the same.
							2. **Sandbox Projects**
							If your working an multiple Projects it let’s you Sandbox each one and keep them separat good for security and eliminates potential conflicts between different Projects.
							3. **It just works**
							And lastly it makes it easier to get going with somebody else in that projects. You don’t have to install all of the tools and dependencies to that the Project needs. You just have to spin up the virtual machine put your code inside and it works.

						</aside>
					</section>
					<section>
						<h2>Containers</h2>
						<div class="container">
							<ul>
								<li>os</li>
								<li>config</li>
								<li>code</li>
								<li>...</li>
							</ul>
						</div>
						<aside class="notes">
							Docker gives you these advantages but without that overhead and hassle of running and managing a virtual machine.
							Instead we have containers. The code and environments are all inside the container. But a Container is not a full virtual machine.
						</aside>
					</section>
					<section>
						<h2>Docker and classic VM Comparison</h2>
						<img class="no-boarder" data-src="images/vm-vs-docker-container.png" height="400pt" width="700pt"/>
						<aside class="notes">
							When you have a full virtual machine, each machine gets it full operating system including the Kernel.
							The Kernel is like the core of the operating system and controls the low level stuff and this is quiet resource heavy on the source machine.

							Container however they all use the host machines kernel and everything on top of that is still separated,
							everything that makes a linux distribution unique, because all linux distributions ubuntu,
							debian etc are all build on the same kernel.

							Docker uses special features of the unix filesystem to create this isolated environments.
							And as a result a Container can startup in seconds I supposed in minutes.
							They uses few resources taking up less diskspace und using less memory.
						</aside>
					</section>
					<section>
						<h2>Image, Container, Instance Dockerfile WTF?!</h2>
						<img class="no-boarder" data-src="images/image-container.png" height="400pt" width="700pt"/>

						<aside class="notes">
							So a container is a running instance of an image. An image is a template for creating the environment you want and a snaptshot of the system at a particular time.

							So it’s got the operating System, the software, the application code all bundled up in a file.

						</aside>
					</section>
					<section>
						<h2>Image, Container, Instance Dockerfile WTF?!</h2>
						<img class="no-boarder" data-src="images/dockerfile-image.png" height="400pt" width="700pt"/>
						<aside class="notes">
							Images are defined using a Dockerfile. A Dockerfile is a textfile with a list of steps to perform, to create the image. For example
							- configure the operating system
							- install the software you need
							- copy the project files into the right places
							- etc

							So you have the Dockerfile, so you build that and you get an image which you you can run to get the containers.
						</aside>
					</section>
				</section>
				<section>
					<section>
					<h2>Hands on</h2>
					<p>dockerize this presentation</p>
					<ol>
						<li>create Dockerfile</li>
						<li>build it</li>
						<li>run it</li>
					</ol>
					<aside class="notes">

					</aside>
					</section>
					<section>
						<h2>creating a Dockerfile</h2>
						<pre><code class="hljs" data-trim contenteditable>
FROM node:4.6.2-slim

MAINTAINER Marc Nützel &lt;marc.nuetzel@dbschenker.com&gt;
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        git && \
    rm -rf /var/lib/apt/lists/* && \
    git clone https://github.com/heyimMarc/docker-presentation.git

WORKDIR /docker-presentation
RUN npm install --silent
EXPOSE 8000
USER nobody

CMD ["npm", "start"]
					</code></pre>
						<aside class="notes">
							Ok let’s start with creating a Dockerfile.
						</aside>
					</section>
					<section>
						<h2>FROM</h2>
						<pre><code class="hljs" data-trim contenteditable>
FROM &lt;image&gt;
FROM &lt;image&gt:&lt;tag&gt;
FROM &lt;image&gt@&lt;digest&gt;
						</code></pre>
						<ul>
							<li>must be first non-comment instruction</li>
							<li>can appear multiple times within a single Dockerfile</li>
							<li>The tag or digest values are optional.</li>
						</ul>
						<aside class="notes">
							Let me describe the instructions I’ve used in this Dockerfile.

							The FROM instruction sets the Base Image for subsequent instructions.
							As such, a valid Dockerfile must have FROM as its first instruction.
							The image can be any valid image – it is especially easy to start
							by pulling an image from the Public Repositories.
						</aside>
					</section>
					<section>
						<h2>MAINTAINER</h2>
						<pre><code class="hljs" data-trim contenteditable>
MAINTAINER &lt;name&gt;
						</code></pre>
						just the author of the image ;)
						<aside class="notes">
							The MAINTAINER instruction allows you to set the Author field of the generated images.
						</aside>
					</section>
					<section>
						<h2>RUN</h2>
						<pre><code class="hljs" data-trim contenteditable>
RUN &lt;command&gt;
						</code></pre>
						<ul>
							<li>will execute commands</li>
							<li>commits the result to the image</li>
						</ul>
						<aside class="notes">
							The RUN instruction will execute any commands in a new layer on top of the current image and commit
							the results. The resulting committed image will be
							used for the next step in the Dockerfile.
						</aside>
					</section>
					<section>
						<h2>WORKDIR</h2>
						<pre><code class="hljs" data-trim contenteditable>
WORKDIR /path/to/workdir
						</code></pre>
						<ul>
							<li>sets the working directory for
								<ul>
									<li>RUN</li>
									<li>CMD</li>
									<li>ENTRYPOINT</li>
									<li>COPY</li>
									<li>ADD</li>
								</ul></li>
							<li>creates directory if doesn't exists</li>
						</ul>
						<aside class="notes">
							The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT,
							COPY and ADD instructions that follow it in the Dockerfile.
							If the WORKDIR doesn’t exist, it will be created even if it’s not used in any subsequent
							Dockerfile instruction.
						</aside>
					</section>

					<section>
						<h2>EXPOSE</h2>
						<pre><code class="hljs" data-trim contenteditable>
EXPOSE &lt;port&gt;
						</code></pre>
						<ul>
							<li>informs Docker that container listens</li>
							<li>does not make the ports accessible on host</li>
						</ul>
						<aside class="notes">
							The EXPOSE instruction informs Docker that the container listens on the specified
							network ports at runtime.
							EXPOSE does not make the ports of the container accessible to the host.
							To do that, you must use either the -p flag to publish a range of ports
							or the -P flag to publish all of the exposed ports.
							You can expose one port number and publish it externally under another number.
						</aside>
					</section>

					<section>
						<h2>CMD</h2>
						<pre><code class="hljs" data-trim contenteditable>
CMD ["executable","param1","param2"]
						</code></pre>
						<ul>
							<li>provide defaults for an executing container</li>
							<li>there can only be one CMD instruction in a Dockerfile</li>
							<img class="no-boarder" data-src="images/highlander.jpg" height="300pt" width="400pt"/>
						</ul>
						<aside class="notes">
							The main purpose of a CMD is to provide defaults for an executing container.
							These defaults can include an executable, or they can omit the executable,
							in which case you must specify an ENTRYPOINT instruction as well.
							But we will not go into the ENTRYPOINT instruction in this Techtalk.

							CMD is like the Highlander, there can only be one!
						</aside>
					</section>

					<section>
						<h2>USER</h2>
						<pre><code class="hljs" data-trim contenteditable>
USER daemon
						</code></pre>
						<ul>
							<li>sets name or UID to use when running the image</li>
							<li>and for any RUN, CMD and ENTRYPOINT instrcution that follows</li>
						</ul>
						<aside class="notes">
							The USER instruction sets the user name or UID to use when
							running the image and for any RUN, CMD and ENTRYPOINT instructions that
							follow it in the Dockerfile.
						</aside>
					</section>

					<section>
						<h2>Bla! bla! bla!, please build the image</h2>
						<pre><code class="hljs" data-trim contenteditable>
docker build -t mnuetzel/techtalk-docker .
						</code></pre>
						<aside class="notes">

						</aside>
					</section>

					<section>
						<h2>What happens during the build?</h2>
						<pre><code class="hljs" data-trim contenteditable>
Sending build context to Docker daemon 2.048 kB
						</code></pre>
						<aside class="notes">
							So what are we seeing here?
							Docker starts sending the build context to the Docker daemon.
							What does that mean?
							Quick and dirty answer: the client is tar/compressing the directory (and all subdirectories)
							where you executed docker build. Yeah, that's right. If you execute this in your root directory,
							your whole drive will get tar'd and sent to the docker daemon.
							Generally that's a mistake you only make once.
						</aside>
					</section>
					<section>
						<h2>Layering</h2>
						<pre><code class="hljs" data-trim contenteditable>
Step 1 : FROM node:4.6.2-slim
 ---> ac75fb1960cc
Step 2 : MAINTAINER Marc Nützel &lt;marc.nuetzel@dbschenker.com&gt;
 ---> Using cache
 ---> 16d25b1aae18
Step 3 : RUN apt-get update &&     apt-get install -y --no-install-recommends         git &&     rm -rf /var/lib/apt/lists/* &&     git clone https://github.com/heyimMarc/docker-presentation.git
 ---> Using cache
 ---> 42ee8cce8add

						</code></pre>
						<aside class="notes">
							The final image consists of n intermediate images as we can see.
							Those layers (or intermediate images or whatever you call them) have some benefits.
							Once we build them, Docker will reuse them for new builds. This makes the builds much faster.
							This is great for continous integration, where we want to build an image at the end of each successful build.
							But the build is not only faster, the images are also smaller, since intermediate images are shared
							between images.

							But maybe the best things are rollbacks: since every image contains all of its building steps, we can easily go back to a previous step if we want so. This can be done tagging a certain layer.

						</aside>
					</section>

					<section>
						<h2>Run the container</h2>
						<pre><code class="hljs" data-trim contenteditable>
docker run -d -p 80:8000 --name techtalk mnuetzel/techtalk-docker
						</code></pre>
						<aside class="notes">
							So let’s start the container, we will bind the exposed port 8000 to port 80 of my local machine and run this container detached. At least we give the container a name.

							Start the container and show it with  docker ps -a
							Show the application in browser, stop container, reload browser.

							As u can see, the container is running and serving the application.
							We have now dockerized our first application.
						</aside>
					</section>
				</section>

				<section>
					<section>
						<h2>docker-compose</h2>

						<ul>
							<li>defining and running complex applications with Docker</li>
							<li>defines a multi-container application in a single file</li>
							<li>spins them up in a single command</li>
						</ul>

						<aside class="notes">

						</aside>
					</section>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'socket.io/socket.io.js', async: true },
                    { src: 'plugin/notes-server/client.js', async: true }
				]
			});
		</script>
	</body>
</html>
