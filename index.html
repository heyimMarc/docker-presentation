<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Schenker Techtalk - Docker</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css">
		<link rel="stylesheet" href="css/theme/schenker-theme.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
	<?php echo "Hello ".($_ENV["NAME"]?$_ENV["NAME"]:"world")."!"; ?>
	<div class="logo"></div>
		<div class="reveal">

			<div class="slides">
				<section>
					<h2>Schenker AG TechTalk</h1>
					<h4>Docker</h3>
						<img class="no-boarder" data-src="images/docker.svg" height="150pt" width="150pt">
						<aside class="notes">
							Keep calm and breath Marc :) and please don't forget to introduce yourself.
						</aside>
				</section>
				<section>
					<section>
						<h2>What is Docker?</h2>
						<img class="no-boarder" data-src="images/isolation.jpg" height="300pt" width="300pt"/>
						<aside class="notes">
							Docker is a Tool for running Applications in an isolated environment.<br/><br/>
							It gives you advantages similar running your application inside of a virtual machine.
						</aside>
					</section>
					<section>
						<ol>
							<li>same environment</li>
							<li>sandbox projects</li>
							<li>it just works</li>
						</ol>

						<aside class="notes">
							1.
							Some of those advantages are, your app always runs in exactly the same environment so you don’t get inconsistencies and how it behaves.
							If it works on your computer, it works on every computer, it works on the live server and always acts the same.
							<br/><br/>
							2.
							If your working an multiple Projects it let’s you Sandbox each one and keep them separat good for security and eliminates potential conflicts between different Projects.
							<br/><br/>
							3.
							And lastly it makes it easier to get going with somebody else in that projects. You don’t have to install all of the tools and dependencies to that the Project needs. You just have to spin up the virtual machine put your code inside and it works.

						</aside>
					</section>
					<section>
						<h2>Containers</h2>
						<div class="container">
							<ul>
								<li>os</li>
								<li>config</li>
								<li>code</li>
								<li>...</li>
							</ul>
						</div>
						<aside class="notes">
							Docker gives you these advantages but without that overhead and hassle of running and managing a virtual machine.<br/><br/>
							Instead we have containers. The code and environments are all inside the container. <br/><br/>
							But a Container is not a full virtual machine.
						</aside>
					</section>
					<section>
						<h2>Docker and classic VM Comparison</h2>
						<img class="no-boarder" data-src="images/vm-vs-docker-container.png" height="400pt" width="700pt"/>
						<aside class="notes">
							When you have a full virtual machine, each machine gets it full operating system including the Kernel.<br/>
							<br/>The Kernel is like the core of the operating system and controls the low level stuff and this is quiet resource heavy on the source machine.
							<br/><br/>
							Container however they all use the host machines kernel and everything on top of that is still separated,
							everything that makes a linux distribution unique, because all linux distributions ubuntu,
							debian etc are all build on the same kernel.
							<br/><br/>
							Docker uses special features of the unix filesystem to create this isolated environments.
							<br/><br/>
							And as a result a Container can startup in seconds I supposed in minutes.
							<br/><br/>
							They uses few resources taking up less diskspace und using less memory.
						</aside>
					</section>
					<section>
						<h2>Image, Container, Instance Dockerfile WTF?!</h2>
						<img class="no-boarder" data-src="images/image-container.png" height="400pt" width="700pt"/>

						<aside class="notes">
							So a container is a running instance of an image. <br/><br/>
							An image is a template for creating the environment you want and a snaptshot of the system at a particular time.<br/><br/>

							So it’s got the operating System, the software, the application code all bundled up in a file.

						</aside>
					</section>
					<section>
						<h2>Image, Container, Instance Dockerfile WTF?!</h2>
						<img class="no-boarder" data-src="images/dockerfile-image.png" height="400pt" width="700pt"/>
						<aside class="notes">
							Images are defined using a Dockerfile.<br/>
							A Dockerfile is a textfile with a list of steps to perform, to create the image.
							<br/>For example
							<ul>
								<li>configure the operating system</li>
								<li>install the software you need</li>
								<li>copy the project files into the right places</li>
								<li>etc</li>
							</ul>
							So you have the Dockerfile, so you build that and you get an image which you you can run to get the containers.
						</aside>
					</section>
				</section>
				<section>
					<section>
					<h2>Hands on</h2>
					<p>dockerize this presentation</p>
					<ol>
						<li>create Dockerfile</li>
						<li>build it</li>
						<li>run it</li>
					</ol>
					<aside class="notes">

					</aside>
					</section>
					<section>
						<h2>creating a Dockerfile</h2>
						<pre><code class="hljs" data-trim contenteditable>
FROM node:4.6.2-slim

MAINTAINER Marc Nützel &lt;marc.nuetzel@dbschenker.com&gt;
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        git && \
    rm -rf /var/lib/apt/lists/* && \
    git clone https://github.com/heyimMarc/docker-presentation.git

WORKDIR /docker-presentation
RUN npm install --silent
EXPOSE 8000

CMD ["npm", "start"]
					</code></pre>
						<aside class="notes">
							Ok let’s start with creating a Dockerfile.
						</aside>
					</section>
					<section>
						<h2>FROM</h2>
						<pre><code class="hljs" data-trim contenteditable>
FROM &lt;image&gt;
FROM &lt;image&gt:&lt;tag&gt;
FROM &lt;image&gt@&lt;digest&gt;
						</code></pre>
						<ul>
							<li>must be first non-comment instruction</li>
							<li>can appear multiple times within a single Dockerfile</li>
							<li>the tag or digest values are optional.</li>
						</ul>
						<aside class="notes">
							Let me describe the instructions I’ve used in this Dockerfile.<br/>

							The FROM instruction sets the Base Image for subsequent instructions.<br/>
							As such, a valid Dockerfile must have FROM as its first instruction.<br/>
							The image can be any valid image – it is especially easy to start
							by pulling an image from the Public Repositories.
						</aside>
					</section>
					<section>
						<h2>MAINTAINER</h2>
						<pre><code class="hljs" data-trim contenteditable>
MAINTAINER &lt;name&gt;
						</code></pre>
						just the author of the image ;)
						<aside class="notes">
							The MAINTAINER instruction allows you to set the Author field of the generated images.
						</aside>
					</section>
					<section>
						<h2>RUN</h2>
						<pre><code class="hljs" data-trim contenteditable>
RUN &lt;command&gt;
						</code></pre>
						<ul>
							<li>will execute commands</li>
							<li>commits the result to the image</li>
						</ul>
						<aside class="notes">
							The RUN instruction will execute any commands in a new layer on top of the current image and commit
							the results.
							<br/><br/>
							The resulting committed image will be
							used for the next step in the Dockerfile.
						</aside>
					</section>
					<section>
						<h2>WORKDIR</h2>
						<pre><code class="hljs" data-trim contenteditable>
WORKDIR /path/to/workdir
						</code></pre>
						<ul>
							<li>sets the working directory for
								<ul>
									<li>RUN</li>
									<li>CMD</li>
									<li>ENTRYPOINT</li>
									<li>COPY</li>
									<li>ADD</li>
								</ul></li>
							<li>creates directory if doesn't exists</li>
						</ul>
						<aside class="notes">
							The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT,
							COPY and ADD instructions that follow it in the Dockerfile.<br/><br/>

							If the WORKDIR doesn’t exist, it will be created even if it’s not used in any subsequent
							Dockerfile instruction.
						</aside>
					</section>

					<section>
						<h2>EXPOSE</h2>
						<pre><code class="hljs" data-trim contenteditable>
EXPOSE &lt;port&gt;
						</code></pre>
						<ul>
							<li>informs Docker that container listens</li>
							<li>does not make the ports accessible on host</li>
						</ul>
						<aside class="notes">
							The EXPOSE instruction informs Docker that the container listens on the specified
							network ports at runtime.<br/><br/>
							EXPOSE does not make the ports of the container accessible to the host.
							<br/><br/>
							To do that, you must use either the -p flag to publish a range of ports
							or the -P flag to publish all of the exposed ports.
							<br/><br/>
							You can expose one port number and publish it externally under another number.
						</aside>
					</section>

					<section>
						<h2>CMD</h2>
						<pre><code class="hljs" data-trim contenteditable>
CMD ["executable","param1","param2"]
						</code></pre>
						<ul>
							<li>provide defaults for an executing container</li>
							<li>there can only be one CMD instruction in a Dockerfile</li>
							<img class="no-boarder" data-src="images/highlander.jpg" height="300pt" width="400pt"/>
						</ul>
						<aside class="notes">
							The main purpose of a CMD is to provide defaults for an executing container.<br/><br/>
							These defaults can include an executable, or they can omit the executable,
							in which case you must specify an ENTRYPOINT instruction as well.<br/><br/>
							But we will not go into the ENTRYPOINT instruction in this Techtalk.
							<br/><br/>
							CMD is like the Highlander, there can only be one!
						</aside>
					</section>

					<section>
						<h2>Let's build the image</h2>
						<pre><code class="hljs" data-trim contenteditable>
docker build -t mnuetzel/techtalk-docker .
						</code></pre>
						<aside class="notes">

						</aside>
					</section>

					<section>
						<h2>What happens during the build?</h2>
						<pre><code class="hljs" data-trim contenteditable>
Sending build context to Docker daemon 2.048 kB
						</code></pre>
						<aside class="notes">
							So what are we seeing here?<br/><br/>
							Docker starts sending the build context to the Docker daemon.<br/><br/>
							What does that mean?<br/><br/>
							Quick and dirty answer: the client is tar/compressing the directory (and all subdirectories)
							where you executed docker build. If you execute this in your root directory,
							your whole drive will get tar'd and sent to the docker daemon.<br/><br/>
							Generally that's a mistake you only make once.
						</aside>
					</section>
					<section>
						<h2>Layering</h2>
						<pre><code class="hljs" data-trim contenteditable>
Step 1 : FROM node:4.6.2-slim
 ---> ac75fb1960cc
Step 2 : MAINTAINER Marc Nützel &lt;marc.nuetzel@dbschenker.com&gt;
 ---> Using cache
 ---> 16d25b1aae18
Step 3 : RUN apt-get update &&     apt-get install -y --no-install-recommends         git &&     rm -rf /var/lib/apt/lists/* &&     git clone https://github.com/heyimMarc/docker-presentation.git
 ---> Using cache
 ---> 42ee8cce8add

						</code></pre>
						<aside class="notes">
							The final image consists of n intermediate images as we can see.<br/><br/>
							Those layers (or intermediate images or whatever you call them) have some benefits.<br/><br/>
							Once we build them, Docker will reuse them for new builds. This makes the builds much faster.<br/><br/>
							This is great for continous integration, where we want to build an image at the end of each successful build.<br/><br/>
							But the build is not only faster, the images are also smaller, since intermediate images are shared
							between images.

							But maybe the best things are rollbacks: since every image contains all of its building steps, we can easily go back to a previous step if we want so. This can be done tagging a certain layer.

						</aside>
					</section>

					<section>
						<h2>Run the container</h2>
						<pre><code class="hljs" data-trim contenteditable>
docker run -d -p 80:8000 --name techtalk mnuetzel/techtalk-docker
						</code></pre>
						<aside class="notes">
							So let’s start the container, we will bind the exposed port 8000 to port 80 of my local machine and run this container detached.<br/><br/>
							At least we give the container a name.
							<br/><br/>
							Start the container and show it with  docker ps -a
							<br/><br/>
							Show the application in browser, stop container, reload browser.
							<br/><br/>
							As u can see, the container is running and serving the application.
							<br/><br/>
							We have now dockerized our first application.
						</aside>
					</section>
				</section>

				<section>
					<section>
						<h2>docker-compose</h2>

						<ul>
							<li>defining and running complex applications with Docker</li>
							<li>defines a multi-container application in a single file</li>
							<li>spins them up in a single command</li>
						</ul>

						<aside class="notes">
							Composing the application with Docker Compose.<br/><br/>
							Compose is a tool for defining and running complex applications with Docker.<br/><br/>
							It can get pretty tedious to build the images, run and link containers using individual commands, <br/>
							especially when you are dealing with many. Docker Compose lets you define a multi-container application in a single file, and spin up the application with a single command.
						</aside>
					</section>

					<section>
						<h2>Let's extend this presentation application</h2>
						<ol>
							<li>add a loadbalancer</li>
							<li>scale the presentation application</li>
						</ol>
						<img class="no-boarder" data-src="images/compose.png" height="280pt" width="400pt"/>
						<aside class="notes">
							Let's extend this presentation application.<br/><br/>
							I would like to add a loadbalancer and scale the application afterwards.
						</aside>
					</section>

					<section>
						<h2>The docker-compose.yml</h2>
						<pre><code class="hljs" data-trim contenteditable>
version: '2'
services:
  web:
    build: .
    ports:
      - 8000
    networks:
      - front-tier

  lb:
    image: dockercloud/haproxy
    ports:
      - 80:80
    links:
      - web
    networks:
      - front-tier
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

networks:
  front-tier:
    driver: bridge
						</code></pre>
						<aside class="notes">
							The docker-compose file is written in YAML.<br/>
							I've defined 2 Services web (our web application) and lb which is our loadbalancer.<br/>
							Ive also created a bridged network and attached both services to it.<br/>
						</aside>

					</section>

					<section>
						<h2>Let the magic begin</h2>
						<pre><code class="hljs" data-trim contenteditable>
docker-compose up -d
						</code></pre>

						<pre><code class="hljs" data-trim contenteditable>
docker-compose scale web=3
						</code></pre>
						<aside class="notes">
							With a single command, Docker Compose will build the required images,
							expose the required ports, run and link the containers
							as defined in the YAML.
							All you need to do is run docker-compose up!
							And your container application is up and running.
						</aside>
					</section>

					<section>
						<h2>Summary</h2>
						<ol>
							<li>we dockerized our application</li>
							<li>run a virtual instance</li>
							<li>created a cluster with a loadbalancer
							<ul><li>...on a single machine :(</li></ul>
							</li>
						</ol>
						<aside class="notes">
							We have dockerized our application.
							We started that virtual instance.
							And we created a cluster, but on a single machine.
						</aside>
					</section>
				</section>

				<section>
					<section>
						<h2>Docker Machine and Docker Swarm</h2>

						<aside class="notes">
							Let's go forward with docker machine and docker swarm.
							Starting with docker machine.
						</aside>
					</section>

					<section>
						<h2>What is Docker Machine?</h2>
						<ul>
							<li>installs Docker Engine on virtual hosts</li>
							<li>manage the hosts</li>
							<li>creates hosts</li>
						</ul>

						<aside class="notes">
							Docker Machine is a tool that lets you install Docker Engine on virtual hosts,<br/>
							and manage the hosts with docker-machine commands.<br/><br/>
							You can use Machine to create Docker hosts on your local Mac or<br/>
							Windows box, on your company network, in your data center, or on cloud providers
							like AWS.
						</aside>
					</section>

					<section>
						<h2>Let's create our first vHost</h2>
						<pre><code class="hljs" data-trim contenteditable>
docker-machine create -d virtualbox demovhost
						</code></pre>

						<aside class="notes">
							Docker-machine is now creating the virtualhost with the virtualbox driver.<br/><br/>
							Docker-machine installs docker and is doing the ssh key exchange.<br/><br/>

							Show it in virtualbox<br/>
							do a docker-machine ls<br/>
							docker-machine ssh demovhost<br/>
							docker --version<br/>
							<br/>
							create 3 swarm nodes than go on with the presentation<br/>
							<br/>
							docker-machine create -d virtualbox node-0<br/>
							docker-machine create -d virtualbox node-1<br/>
							docker-machine create -d virtualbox node-2<br/>
						</aside>
					</section>
					<section>
						<h2>Docker Swarm</h2>
						<img class="no-boarder" data-src="images/docker-swarm-hero2.png" height="200pt" width="200pt"/>
						<ul>
							<li>native clustering for docker</li>
							<li>turns a pool of docker hosts into a single</li>
							<li>docker swarm servers docker API</li>
						</ul>
						<aside class="notes">
							Docker Swarm is native clustering for Docker.<br/>
							It turns a pool of Docker hosts into a single, virtual Docker host.<br/><br/>
							Because Docker Swarm serves the standard Docker API, any tool that already communicates
							with a Docker daemon can use Swarm to transparently scale to multiple hosts.
						</aside>
					</section>

					<section>
						<h2>Bringing the presentation application to the swarm</h2>
						<img class="no-boarder" data-src="images/docker-swarm-hero2.png" height="200pt" width="200pt"/>
						<ol>
							<li>lets create 3 vHosts</li>
							<li>setup the swarm</li>
							<li>deploy the application</li>
						</ol>
						<aside class="notes">
							docker-machine ssh node-0<br/><br/>
							docker swarm init --advertise-addr eth1<br/><br/>
							get token and execute on other machine<br/><br/>
							check with: docker node ls<br/><br/>
							docker service create --name techtalk -p 80:8000 --replicas 3 marcnuetzel/techtalk-docker<br/><br/>
							docker service ls<br/><br/>
							docker-machine env node-0<br/><br/>
							show website<br/><br/>
							docker service scale techtalk=9<br/><br/>
							login to every node  and show container with docker ps<br/><br/>
							leave swarm and show that swarm moves the container<br/><br/>
							docker swarm leave<br/><br/>
						</aside>
					</section>
				</section>
				<section>
					<section>
						<h2>Where can docker support?</h2>
						<ol>
							<li>Development
							<ul>
								<li>keeps you local environment clean</li>
								<li>saves time (setup oracle database in seconds)</li>
							</ul>
							</li>
							<li>Release
								<ul>
									<li>simplifies your release notes (just run the container)</li>
									<li>don't worry about inconsistencies between dev ond prod environments anymore</li>
								</ul>
							</li>
						</ol>
						<aside class="notes">
							Docker helps you keep your local development environment clean.<br/><br/>
							Instead of having multiple versions of different services installed such as Java,
							Kafka, Spark, Cassandra, etc.<br/><br/>

							It also saves time, create your image once and run it as often as you like and share it with your friends.<br/><br/>

							It also simplifies your release notes (just run it) don't worry about inconsistencies between different environments anymore.<br/><br/>
						</aside>
					</section>

					<section data-background="http://i.giphy.com/90F8aUepslB84.gif">
						<h2 style="color: white">Have fun swimming with the whales!</h2>
						<aside class="notes">

						</aside>
					</section>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'socket.io/socket.io.js', async: true },
                    { src: 'plugin/notes-server/client.js', async: true }
				]
			});
		</script>
	</body>
</html>
